
fastapi
python-multipart
uvicorn[standard]
websockets>=10.0
transformers
torch
numpy
torchaudio
pillow>=10.0
librosa
accelerate
annotated-types==0.7.0
anyio==4.11.0
certifi==2025.10.5
charset-normalizer==3.4.4
click==8.3.0
fastapi==0.119.0
filelock==3.20.0
fsspec==2025.9.0
h11==0.16.0
hf-xet==1.1.10
httptools==0.7.1
huggingface-hub==0.35.3
idna==3.11
Jinja2==3.1.6
MarkupSafe==3.0.3
mpmath==1.3.0
networkx==3.5
numpy==2.3.4
# NVIDIA CUDA libraries for RTX 5090 support
nvidia-cublas-cu12>=12.4.5.8
nvidia-cuda-cupti-cu12>=12.4.127
nvidia-cuda-nvrtc-cu12>=12.4.127
nvidia-cuda-runtime-cu12>=12.4.127
nvidia-cudnn-cu12>=9.1.0.70
nvidia-cufft-cu12>=11.2.1.3
nvidia-cufile-cu12>=1.13.1.3
nvidia-curand-cu12>=10.3.5.147
nvidia-cusolver-cu12>=11.6.1.9
nvidia-cusparse-cu12>=12.3.1.170
nvidia-cusparselt-cu12>=0.6.2
nvidia-nccl-cu12>=2.21.5
nvidia-nvjitlink-cu12>=12.4.127
nvidia-nvshmem-cu12>=3.3.20
nvidia-nvtx-cu12>=12.4.127
packaging==25.0
pillow==12.0.0
pydantic==2.12.3
pydantic_core==2.41.4
python-dotenv==1.1.1
python-multipart==0.0.20
PyYAML==6.0.3
regex==2025.9.18
requests==2.32.5
safetensors==0.6.2
sniffio==1.3.1
starlette==0.48.0
sympy==1.13.1
tokenizers==0.22.1
# PyTorch with RTX 5090 support (CUDA 12.4+)
torch>=2.7.0
torchaudio>=2.7.0
torchvision>=0.22.0
tqdm==4.67.1
transformers==4.57.1
triton==3.2.0
typing-inspection==0.4.2
typing_extensions==4.15.0
urllib3==2.5.0
uvicorn==0.38.0
uvloop==0.22.1
watchfiles==1.1.1
websockets==15.0.1